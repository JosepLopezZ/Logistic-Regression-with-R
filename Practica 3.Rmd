---
title: "Práctica 3 - Regresión Logística"
author: "Josep Lopez Lizarte"
date: "26/10/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Carga de librerías necesarías para la práctica:

```{r, echo=TRUE, warning=FALSE}
function_install_packages <- function(x)
{
  for(i in x)
  {
    if(!require(i, character.only = TRUE))
    {
      install.packages(i, dependencies = TRUE)
      require(i, character.only = TRUE)
    }
  }
}

function_install_packages(c("dplyr", "ggplot2", "corrplot", "ggcorrplot", "e1071", "GGally", "tidyverse", 
                            "ggpubr", "base", "car", "MASS", "leaps", "hier.part", "gvlma", "lmtest",
                            "caTools", "pROC", "ROCR", "WRS2", "readxl", "stringi", "digest", "VIM"))

```

Importamos el dataframe correspondiente al dataset winequality-white, que contiene la información relativa a al calidad de determinados vinos blancos en función de características propias de su naturaleza, tales como la acidez, el PH, la densidad, la concentración de alcohol o el azúcar, entre otras.

```{r, echo=TRUE, warning=FALSE}
dataset1 <- read.csv(sep = ";","C:/Users/34662/Escritorio/MÁSTER DATA SCIENCE/Material Máster Data Science/2 - Estadística/Carpeta Trabajos y borradores prácticas/PRACTICA 3/winequality-white.csv")
str(dataset1)
names(dataset1)

head(dataset1)
summary(dataset1)
```

Nos documentamos con la función str() del tipo qué son las variables que manejamos, observamos los títulos de las mismas y vemos los datos principales de ellas a través de sumary().

**1) Realizar una breve auditoría de los datos, determinando las cantidades de registros duplicados y vacíos, y eliminando esas duplicidades para generar la tabla protagonista del   problema.**

```{r, echo=TRUE, warning=FALSE}
aggr(dataset1, numbers = TRUE)
summary(aggr(dataset1, numbers = TRUE)) 
```

Obtenemos si existen valores perdidos o vacíos en nuestro dataframe. En este caso no los hay ya que el conteo es 0.

Para saber si existen  valores nulos, podemos hacerlo a nivel global de todo el dataframe o generando una función y hacerlo manualmente variable por variable
```{r, echo=TRUE, warning=FALSE}
sapply(dataset1, function(x) all(!is.na(x)))
```

Conocemos a rasgos generales, que no hay ninguna variable que nos devuelva FALSE, por lo que no existen columnas con almenos un registro con valor nulo.
Por otro lado, aplicamos la función:
```{r, echo=TRUE, warning=FALSE}
NA_COUNT<-function(x){
  for(i in 1:length(x)){
    if(is.na(x[i])) {
      print("Algun valor de la variable es nulo")
      break}
  }}

NA_COUNT(dataset1$fixed.acidity)
NA_COUNT(dataset1$volatile.acidity)
NA_COUNT(dataset1$citric.acid)
NA_COUNT(dataset1$residual.sugar)
NA_COUNT(dataset1$chlorides)
NA_COUNT(dataset1$free.sulfur.dioxide)
NA_COUNT(dataset1$total.sulfur.dioxide)
NA_COUNT(dataset1$density)
NA_COUNT(dataset1$pH)
NA_COUNT(dataset1$sulphates)
NA_COUNT(dataset1$alcohol)
NA_COUNT(dataset1$quality)
```

Realizando el ejercicio para cada variable del dataset, ninguna nos devuelve la frase "Algun valor de la variable es nulo", por lo que concluimos que no existen valores nulos.

Procedemos a la detección de duplicados, para así poder limpiarlos y quedarnos con un dataframe sin filas duplicadas. 
```{r, echo=TRUE, warning=FALSE}
nrow(dataset1[duplicated(dataset1), ])
nrow(dataset1[!duplicated(dataset1), ])
```

Ahora ya conocemos el número de filas duplicadas y el que no. Así que podemos generar nuestro dataframe definitivo:

```{r, echo=TRUE, warning=FALSE}
dataset2 <-dataset1[!duplicated(dataset1)&(!is.na(dataset1$quality)), ]
aggr(dataset2, numbers = TRUE)
summary(dataset2$fixed.acidity)
summary(dataset2$volatile.acidity)
summary(dataset2$citric.acid)
summary(dataset2$residual.sugar)
summary(dataset2$chlorides)
summary(dataset2$free.sulfur.dioxide)
summary(dataset2$density)
summary(dataset2$pH)
summary(dataset2$sulphates)
summary(dataset2$alcohol)
summary(dataset2$quality)
```

Comprobamos nuevamente que no haya valores perdidos en nuestro nuevo dataframe y, de manera manual, que no existan registros nulos en ninguna variable antes de proseguir con la práctica. Esto último lo realizamos con la función summary(), la cual nos muestra que no existen Na en ninguna de nuestras variables.

**2) La variable a predecir será la calidad (quality) del vino, con lo que se pretende disponer de este atributo en formato factor (inicialmente admite valores entre 3 y 9, indicando así el grado de calidad).**

Vemos, nuevamente, el tipo de dato que es cada una de nuestras variables:
```{r, echo=TRUE, warning=FALSE}
str(dataset2)
```

Sabiendo que nuestra variable "quality" es un número integro, habrá que convertirlo en factor, asociando a cada valor entre 3 y 9 el grado de calidad:

```{r, echo=TRUE, warning=FALSE}
dataset2$quality <- factor(dataset2$quality, labels = c("Muy_Malo", "Malo", "Regular",
                           "Aceptable", "Bueno", "Muy_bueno", "Excelente"))
str(dataset2)
```

Por lo que ahora cada número de nuestra variable ha quedado asociado de la siguiente manera:

- 3: Muy malo
- 4: Malo
- 5: Regular
- 6: Aceptable
- 7: Bueno
- 8: Muy bueno
- 9: Excelente

Observamos las primeras filas para corroborar el cambio a formato factor:
```{r, echo=TRUE, warning=FALSE}
head(dataset2)
```

**3) Una vez transformada esa variable a formato factor, codificarla de forma que indique alta calidad para todos aquellos valores por encima de 6, y baja calidad para los casos     con etiqueta menor o igual a 6. De este modo, se habr? creado una nueva variable binaria (1/0) que represente la alta o baja calidad de cada registro (el formato deber? ser también factor).**

Generamos la variable cuyos valores serán 1 y 0, donde el 1 representará los vinos de alta calidad y el 0 los vinos de baja calidad.
```{r, echo=TRUE, warning=FALSE}
dataset2$calidad_vino <- ifelse(dataset2$quality=="Muy_Malo", 0,
                                      ifelse(dataset2$quality=="Malo", 0,
                                             ifelse(dataset2$quality=="Regular", 0,
                                                    ifelse(dataset2$quality=="Aceptable", 0,
                                                           ifelse(dataset2$quality=="Bueno", 1,
                                                                  ifelse(dataset2$quality=="Muy_bueno", 1,
                                                                         ifelse(dataset2$quality=="Excelente", 1,
                                                                                "NULL")))))))
head(dataset2)
```

Una vez clasificada la calidad del vino únicamente en 1 si son de alta calidad y en 0 si son de baja calidad, hay que pasar esta variable a formato factor, la generada esta en formato "character"

```{r, echo=TRUE, warning=FALSE}
str(dataset2)
dataset2$calidad_vino <- factor(dataset2$calidad_vino, labels = c("Baja", "Alta"))
str(dataset2)
head(dataset2)
```

Ahora ya disponemos de una variable en formato factor ("calidad_vino"), la cual nos indicará si el vino es de alta o baja calidad de manera directa.

Representamos numéricamente la matriz de correlaciones, cuando la variable "qualitity" es considerada número integro para poderla incluir en la matriz.

```{r, echo=TRUE, warning=FALSE}
cor(dataset1[ , c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)])
```

Y ahora lo hacemos gráficamente, donde queda reflejado que la variable que más influye en la variabilidad de nuestra variable calidad, es el alcohol. El grado de alcohol tiene una alta correlación con la densidad. Y a su vez, la densidad tiene la mayor correlación de la matriz con los azucares residuales.

Mostramos gráfico:

```{r, echo=TRUE, warning=FALSE}
ggcorrplot(cor(dataset1[ , c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)], use="complete.obs"), hc.order=TRUE, type="lower", lab=TRUE)
```

Por otra parte, representamos un gráfico de cajas, donde apreciamos que la concentración de calidad de vino esta calificada entre el 5 y el 6 principalmente, por lo que en general, tenderemos a tener un vino de baja calidad.

```{r, echo=TRUE, warning=FALSE}
boxplot_top <- function(x,y)
{
  stats=boxplot.stats(x)$stats
  f=fivenum(x)
  stats2<-c(f[1],stats,f[5])
  stats3<-c(f[1],f[5])
  
  boxplot(x,main=y,col="steelblue2")
  abline(h=stats[1],lty=2,col="orange")
  abline(h=stats[5],lty=2,col="orange")
  text(rep(1.35,5),stats,labels=c('BIGOTE INFERIOR','PRIMER CUARTIL','MEDIANA','TERCER CUARTIL','BIGOTE SUPERIOR'))
  text(rep(.5,7),stats2,labels=round(stats2,digits=4),cex=0.6)
  text(rep(0.75,2),stats3,labels=c('MÍNIMO','MÁXIMO'))
}

boxplot_top(dataset1$quality, 'Calidad del vino')
```

**4) Determinar los porcentajes de vinos con alta y baja calidad en el cojunto de datos sin duplicados.**

```{r, echo=TRUE, warning=FALSE}
tabla <- table(dataset2$calidad_vino)
addmargins(tabla)
tabla_frec <- prop.table(table(dataset2$calidad_vino))*100
addmargins(tabla_frec)
dim(dataset2)
```

Podemos concluir que de un total de 3961 registros que contiene nuestro dataframe, 3136 son de vinos de baja calidad (un 79,17%), mientras que 825 registros son de alta calidad (un 20,83%).
Sabemos que la mayoría de nuestros registros son vinos de baja calidad en este caso.

Observamos, un boxplot representado gráficamente donde se refleja la concentración de datos según la calidad del vino en función de la calidad facilitada:

```{r, echo=TRUE, warning=FALSE}
ggplot(data = dataset2, aes(x = calidad_vino, y = quality, color = quality)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.1) +
  theme_bw() +
  theme(legend.position = "null")
```

**5) Partir esa misma tabla sin duplicados en dos conjuntos de datos: uno de training (70% de los registros) para construir un modelo predictivo que permita clasificar vinos en función de su alta o baja calidad, y otro de test (30% de los registros) para realizar las correspondientes pruebas de la eficiencia en la predicción.**

Primero indicamos el % de filas que queremos extraer para nuestros dataframe de training, el cual será un 70%.
Utilizamos una semilla (seed) por si más adelante queremos volver a tener este dataframe, con esta función podemos recuperarlo y utilizar el mismo más adelante.

Y generamos, una vez tengamos las condiciones de partición realizadas, los dataframes que utilizaremos para nuestro modelo de regresión logística múltiple:
```{r, echo=TRUE, warning=FALSE}
smp_size <- floor(0.70 * nrow(dataset2))

set.seed(123)
train_ind <- sample(seq_len(nrow(dataset2)), size = smp_size)

train <- dataset2[train_ind, ]
test <- dataset2[-train_ind, ]
```

**6) Desarrollar con el conjunto de training una regresión logística multiple que relacione la variable binaria de la calidad del vino con el resto de variables descriptivas de la tabla.**

Realizamos el modelo de regresión logística múltiple, tenemos que utilizar el comando glm ya que se trata de un modelo lineal generalizado. Esto es causado porque nuestra predicción se trata de algo binario (1 o 0, alta o baja calidad de nuestro vino), por lo que añadiremos en la regresión: family = binomial.

Utilizamos un método de regresión logística ya que nos permite estimar la probabilidad de una variable cualitativa binaria en función de una variable cuantitativa. Una de las principales aplicaciones es la de clasificación binaria, en el que las observaciones se clasifican en un grupo u otro dependiendo del valor que tomen las variables empleadas como predictor.
En esta ocasi?n la regresión lineal no podría efectuarse, ya que al tratarse de una recta, para valores extremos del predictor, se obtendrían para la variable dependendiente valores por debajo de 0 y por encima de 1, lo que estaría en contradicción con el hecho de que las probabilidades siempre están dentro del rango [0,1)

Señalamos que nuestro modelo que relacione nuestra variable calidad del vino con el resto, por lo que ponemos "~." para incluir todas la variables en el modelo.

```{r, echo=TRUE, warning=FALSE}
modelo<-glm(calidad_vino~., data=train, family=binomial)
modelo2 <- update(modelo,.~.-quality)
summary(modelo2)
```

No hemos incorporado la variable "quality" a nuestro modelo de predicción, ya que nos conviene predecir la calidad del vino, por lo que no debemos conocerla de antemano para el modelo. Es una variable que depende 100% de la otra por lo que nos explicaría la totalidad de la variable a predecir. Necesitamos saber si el vino es de alta o baja calidad según la resta de variables de las que disponemos.

**7) Seguir un proceso step para seleccionar las variables más representativas en la predicción. Describir el modelo final resultante.**

A traves del proceso step, el programa selecciona vía p-valor. Con la función step() conocemos de antemano que el modelo más apropiado es el que tiene un valor AIC con valor mínimo de los que el propio programa nos ofrece a observar.

```{r, echo=TRUE, warning=FALSE}
step(modelo2, direction = "backward")    
```

El modelo de regresin logística múltiple con el menor AIC observado es el siguiente:

**calidad_vino** ~ 0.5273 * fixed.acidity -2.624 * volatile.acidity + 0.2384 * residual.sugar - 
    1.769 * chlorides + 0.01884 * free.sulfur.dioxide -0.003883 * total.sulfur.dioxide -
    587.2 * density + 4.18 * pH + 1.944 * sulphates + 0.2464 * alcohol + 561.2

Por lo que para predecir la variable dependiente calidad vino, únicamente descartaremos de nuestro modelo inicial la variable "citric.acid". 

Redefinimos modelo de regresión logística múltiple, para obtener las características de cada variable una vez hecha la limpieza, nuevamente:

```{r, echo=TRUE, warning=FALSE}
modelo_def <- glm(calidad_vino~fixed.acidity + volatile.acidity + residual.sugar + chlorides +
                    free.sulfur.dioxide + total.sulfur.dioxide + density + pH + 
                    sulphates + alcohol, data=train, family = binomial)
summary(modelo_def)
```

Los valores de nuestro modelo de regresión no han variado respecto al introducido más arriba, ya que la regresión ya está aplicada.

Todas las variables predictivas incluídas en el modelo tienen una relación significava con la calidad del vino (p-valor < 0.05), a excepción de "alcohol", la cual si quitasemos del modelo de predicción quedar?a un AIC superior, por lo que la mantenemos en nuestro modelo. Lo mismo sucede con la variable "total.sulfur.dioxide", se aproxima tanto al p-valor~0.05 que es conveniente mantenerla ya que se considera prácticamente significativa para explicar la variable dependiente.

El valor estimado de los coeficientes parciales de correlación calculados por el modelo_def tienen tanto relaciones negativas como positivas con la calidad del vino, por lo que afectan de distinto modo, pero tienen la misma significancia.

Generamos los intervalos de confianza:

```{r, echo=TRUE, warning=FALSE}
confint(modelo_def)
```

En caso de querer los intervalos basados en el error estándar:

```{r, echo=TRUE, warning=FALSE}
confint.default(modelo_def)
```

Procedemos a evaluar el modelo con "Likelihood Ratio":

- Diferencia de residuos: 
```{r, echo=TRUE, warning=FALSE}
dif_residuos <- modelo_def$null.deviance - modelo_def$deviance
paste("Diferencia de residuos:", round(dif_residuos, 4))
```

- Grados de libertad:
```{r, echo=TRUE, warning=FALSE}
df <- modelo_def$df.null - modelo_def$df.residual
paste("Grados de libertad:", df)
```

- P - valor:
```{r, echo=TRUE, warning=FALSE}
p_value <- pchisq(q = dif_residuos,df = df, lower.tail = FALSE)
paste("p-value:", round(p_value, 4))
```

El modelo en conjunto sí es significativo y, acorde a los p-values mostrados en el summary(), también es significativa la contribución al modelo de los distintos predictores.
El P-valor de nuestro "Likelihood ratio" = 0 < 0.05, por lo que nos muestra que nuestro modelo es significativo.

Podemos concluir, extrayendo la importancia en porcentaje de cada una de las variables a la hora de afectar sobre la variabilidad en nuestra variable dependiente. Lo hacemos a traves del siguiente método:

relat.imp.RMSPE=hier.part(train$calidad_vino, train[, 1:11], 
                          family="gaussian", gof="RMSPE", barplot=TRUE)
relat.imp.RMSPE

De donde apreciamos, que las variables densidad y alcohol influyen en más de un 40% sobre la variabilidad de nuestra variable dependiente (calidad del vino), por lo que son las más determinantes de nuestro modelo. 

No representamos la función con R, debido al elevado espacio que supone y dificultad de ejecución. Debido al cálculo de regresiones que generamos, el listado extraído es muy largo.

**8) Generar las probabilidades asociadas a las predicciones que corresponden al cojunto de test. Crear una variable que asigne a cada registro con probabilidad mayor que 1/3 la etiqueta de buen vino, siendo mal vino todo aquel que muestre una probabilidad por debajo o igual a 1/3.**

Generamos el modelo de regresión logística a partir del dataframe test:

```{r, echo=TRUE, warning=FALSE}
modelo3<-glm(calidad_vino~., data=test, family=binomial)
modelo4 <- update(modelo,.~.-quality)
summary(modelo4)

step(modelo4, direction = "backward")  

modelo_def2 <- glm(calidad_vino~fixed.acidity + volatile.acidity + residual.sugar +
                    free.sulfur.dioxide + density + pH + 
                    sulphates, data=test, family = binomial)
summary(modelo_def2)
```

Donde hemos descartado toda variable con p-valor < 0.05 a excepción de free.sulfur.dioxide. Se han descartado ya que haciendo prueba-error hemos observado que este modelo definitivo es el que nos da un valor AIC menor. En el modelo con el dataframe "test" no hemos podido descartar tantas variables como en este caso.

- Comparación de las predicciones con las observaciones:

Para generar predicción: si la probabilidad de buen vino es superior a 0.33 se le asigna al nivel 1 (alta calidad) si la probabilidad es menor, se le asigna un 0 (baja calidad).

Lo hacemos de la siguiente manera:
```{r, echo=TRUE, warning=FALSE}
predicciones <- ifelse(test = modelo_def2$fitted.values > 0.33, 
                       yes = 1, no = 0)

matriz_confusion <- table(modelo_def2$model$calidad_vino, predicciones,
                          dnn = c("Observaciones", "Predicciones"))
matriz_confusion
+((840+120)/(840+120+107+122))*100
```

Concluímos que de un total de 227 vinos de alta calidad en nuestro modelo de regresión (generado a partir del dataframe test), nuestro modelo es capaz de clasificar correctamente el 80,74% de las observaciones de entrenamiento. Si se analiza en detalle cómo se distribuye el error, se aprecia que el modelo solo ha sido capaz de identificar a 120 de los 227 vinos de alta calidad (1). El porcentaje de falsos negativos está por debajo de la mitad, por lo que no está mal, pero es mejorable, el error de nuestro modelo es ciertamente elevado y eso afectar?a a la precisión.

- Procedemos con el verdadero problema, generamos variable de predicción para cada registro a través de nuestro modelo logístico:
  Utilizamos el modelo logístico calculado para el dataframe de test.

```{r, echo=TRUE, warning=FALSE}
test$prediccion <- predict(modelo_def2, test, type = "response")
head(test)
```

Ahora ya podemos apreciar que hemos obtenido una nueva variable (prediccion) en la que nos aparece la probabilidad de cada registro.
Definimos cada uno de los registros y le asignamos una tipo de calidad (alta o baja) según si la probabilidad es mayor de 1/3 o está por debajo.

```{r, echo=TRUE, warning=FALSE}
test$prediccion_calidad <- ifelse(test$prediccion > 1/3, "Alta",
                                  ifelse(test$prediccion <= 1/3, "Baja",
                                         "NULL"))
head(test)
```

Generamos un pequeño histograma para reflejar que se predicen en mayor medida casos donde el vino es de baja calidad. Para generar el gráfico hemos tenido que pasar la variable a tipo numérico y generar otra. Quedando así:

```{r, echo=TRUE, warning=FALSE}
test$pred_calidad_grafico <- ifelse(test$prediccion_calidad == "Baja", 0,
                                    ifelse(test$prediccion_calidad == "Alta", 1,
                                           "NULL"))
test$pred_calidad_grafico <- as.numeric(as.character(test$pred_calidad_grafico))

hist(100*test$pred_calidad_grafico, col="skyblue2",
     main=" resultados modelo glm() sobre datos Test",
     xlab="Probabilidad en % de calidad alta o baja",
     ylab="Frecuencia")
```

**9) Mediante una tabla cruzada, mostrar todas las combinaciones de predicciones y valores reales de la calidad del vino.**

Una vez obtenemos los registros del conjunto de test con dos variables: la real que indica si el vino es de alta o baja calidad, y la que obtenemos a través de la predicción.
Utilizamos la función "table" entre las dos variables: sacamos frecuencias absolutas y relativas.
```{r, echo=TRUE, warning=FALSE}
tabla2 <- table(test$calidad_vino, test$prediccion_calidad)
addmargins(tabla2)

tabla_frec2 <- prop.table(table(test$calidad_vino, test$prediccion_calidad))*100
addmargins(tabla_frec2)
```

Filas = observaciones
Columnas = predicciones

Podemos extraer lo siguiente:

- Cuando el vino es de baja calidad (962 registros), nuestra predicción coincide en declinarse por baja calidad en 842 registros. Esto significa que en este caso tenemos una precisión de que en el 87,52% de los casos, nuestro modelo de predicción concluye en que el vino es de baja calidad cuando realmente es de baja calidad.
  Prácticamente no hay desviación en la predicción con respeto a las observaciones, se considera bastante preciso.

- Cuando el vino es de alta calidad (227 registros), nuestra predicción indica que 118 registros son de alta calidad, indicando que coincide (precisión) en un 51,98% de los casos cuando se trata de predecir vinos de alta calidad. Se equivoca en un 48% aproximadamente nuestra predicción en los casos de alta calidad.

De otra manera, podemos realizar una matriz de confusión:

Esta matriz se obtiene de generar un nuevo dataframe, el cual tiene 2 columnas, la de calidad del vino observada y la predicción de la calidad del vino (conjunto test)

```{r, echo=TRUE, warning=FALSE}
prediccion_valor <- predict(modelo_def2, test, type = "response")
prediccion_cal <- ifelse(prediccion_valor>1/3, "Alta", "Baja")
data_matriz <- data.frame(observed = test$calidad_vino,
                          predicted = prediccion_cal)

head(data_matriz)
```

Concentramos nuestros datos en un solo dataframe. Ahora generamos la matriz (no se puede realizar visualmente un gráfico en forma de matriz), que nos indica el número de vinos que en observaciones son de alta calidad, y a través de nuestra predicción tambien coincide la calidad, de igual modo para los de baja calidad.
Con esto podemos detectar la precisión de nuestro modelo de predicción y ver cuan acurada es.

```{r, echo=TRUE, warning=FALSE}
calidad_alta <- sum(data_matriz$observed == "Alta")
calidad_baja <- sum(data_matriz$observed == "Baja")
prediccion_calidad_alta <- sum(data_matriz$predicted == "Alta")
prediccion_calidad_baja <- sum(data_matriz$predicted == "Baja")
total <- nrow(data_matriz)
data.frame(calidad_alta, calidad_baja, prediccion_calidad_alta, prediccion_calidad_baja)
```

De esta forma hemos obtenido los totales de las observaciones y las predicciones, ahora vamos a ver cuanto acierto tiene nuestro modelo en más detalle.

```{r, echo=TRUE, warning=FALSE}
tp<-sum(data_matriz$observed=="Alta" & data_matriz$predicted=="Alta")
tn<-sum(data_matriz$observed=="Baja" & data_matriz$predicted=="Baja")
fp<-sum(data_matriz$observed=="Baja" & data_matriz$predicted=="Alta")
fn<-sum(data_matriz$observed=="Alta" & data_matriz$predicted=="Baja")
data.frame(tp,tn,fp,fn)
```

Una vez disponemos de una matriz al completo entre las observaciones y las predicciones de nuestro dataframe, y disponemos de los totales y los valores internos, podemos proceder a realizar los cálculos pertinentes que nos indicarán la sensibilidad de nuestro modelo, la precisión, el error, etc.

```{r, echo=TRUE, warning=FALSE}
accuracy <- (tp+tn)/total
error_rate <- (fp+fn)/total
sensitivity <- tp/calidad_alta
especificity <- tn/calidad_baja
precision <- tp/prediccion_calidad_alta
npv <- tn / prediccion_calidad_baja
data.frame(accuracy,error_rate,sensitivity,especificity,precision,npv)
```

Extraemos las siguientes conclusiones con respeto a nuestras predicciones a través de un modelo logístico múltiple:

- La exactitud (accuracy) es de un 80.74%, es equivalente al porcentaje de la data clasificado correctamente. Considero que es un porcentaje elevado.
- La tasa de error nos da que es del 19.25%, siendo el equivalente al porcentaje de la data que clasifica incorrectamente.
- La sensibilidad, nos indica la tasa de vinos de calidad alta predicha que realmente lo son, es decir, la exhaustividad de la predicción. En nuestro caso es del 51,98%.
- En cuanto a la especificidad, es el contrario, nos indica la tasa de vinos de baja calidad predichos que realmente son de baja calidad. Se encuentra en un 87,55%, una variable que se predice con una elevada precisión.
- La precisión nos indica que cuando nuestro modelo predice vinos de alta calidad, predice correctamente un 49,58%. Por debajo de la mitad.
- En cambio, nvp (valor de predicción negativo) nos indica que el 88,53% de los vinos de baja calidad predichos por el modelo, los predice correctamente.

```{r, echo=TRUE, warning=FALSE}

```



```{r, echo=TRUE, warning=FALSE}

```

